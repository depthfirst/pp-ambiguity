{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import spacy\n",
    "from spacy2folia import spacy2folia\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pp_attachment_ambiguity(parse):\n",
    "    # https://stackoverflow.com/questions/18799036/python-best-way-to-remove-duplicate-character-from-string\n",
    "    step0 = re.sub(r'SBAR \\(IN', 'PP (IN', parse)\n",
    "    step1 = [m[0] for m in re.findall(r'[VNP]P',step0)]\n",
    "    step2 = ''.join(step1)\n",
    "    step3 = ''.join(ch for ch, _ in groupby(step2))\n",
    "    phrase_pattern = step3\n",
    "    \n",
    "    # If no prep phrase, let's not waste time.\n",
    "    if not re.search(r'P',phrase_pattern):\n",
    "        if len(phrase_pattern)>0:\n",
    "            print(\"No preps: {}\".format(phrase_pattern))\n",
    "            print(parse)\n",
    "        return False, 'P'\n",
    "    \n",
    "    # (V, N, P, N) => ambiguous (Pantel&Lin) \n",
    "    # Mary ate a salad with a fork. \n",
    "    # Mary ate a salad with croutons. \n",
    "    match_obj = re.search(r'VNPN', phrase_pattern)\n",
    "    if match_obj:\n",
    "        return True, 'VNPN'\n",
    "    #(V, P, N, P, N) => ambiguous (I made this!) \n",
    "    #I walked with my golf bag to the clubhouse. \n",
    "    #I walked with my golf bag in a pullcart.\n",
    "    match_obj = re.search(r'VPNPN', phrase_pattern)\n",
    "    if match_obj:\n",
    "        return True, 'VPNPN'\n",
    "    # (N, P, N, P, N) => ambiguous (I made this!)\n",
    "    # In at least one image there is a single tree with orange flowers in front of a church with the open door facing forward left.\n",
    "    # ... [tree with orange] flowers in front of a church ...\n",
    "    # ... [tree with orange] flowers with five petals on thick branches... \n",
    "    # ([N, P, {N, P, N], P, N})\n",
    "    match_obj = re.search(r'NPNPN', phrase_pattern)\n",
    "    if match_obj:\n",
    "        return True, 'NPNPN'\n",
    "    # (N, V, P, N) => ambiguous (discovered empirically)\n",
    "    # ... women wearing white bikinis standing next to the water. \n",
    "    # (simplification)\n",
    "    # ... A woman is wearing a bikini cooking on a gas stove. \n",
    "    # ... A woman is holding a spatula cooking in a white bikini. \n",
    "    if re.search(r'NVNVPN', phrase_pattern):\n",
    "        return True, 'NVNVPN'\n",
    "    \n",
    "    # We have now passed all the checks for ambiguity. \n",
    "    \n",
    "    #^(N, P, N, V) => unambiguous (I made this!)\n",
    "    # The man with the beard sells tacos. \n",
    "    match_obj = re.search(r'^NPNV', phrase_pattern)\n",
    "    if match_obj:\n",
    "        print(\"Pattern match (^NPNV=un): {}\".format(phrase_pattern))\n",
    "        print(parse)\n",
    "        return False, '^NPNV'\n",
    "    else:\n",
    "        # ...in the image on the left...\n",
    "        match_obj = re.search(r'PNPN', phrase_pattern)\n",
    "        if match_obj:\n",
    "            print(\"Pattern match (PNPN=un): {}\".format(phrase_pattern))\n",
    "            print(parse)\n",
    "            return False, 'PNPN'\n",
    "        else:\n",
    "            print(\"New pattern: {}\".format(phrase_pattern))\n",
    "    print(parse)\n",
    "    return False, phrase_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_pp_attachment_ambiguity(parse):\n",
    "    ambig, pat = get_pp_attachment_ambiguity(parse)\n",
    "    return ambig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file):\n",
    "    lines = []\n",
    "    with open(file) as text_in:\n",
    "        for line in text_in:\n",
    "            lines.append(line.strip())\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sents = load_text_file('../../data/dev.sent')\n",
    "dev_parses = load_text_file('../../data/dev.parse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sents_and_parses = [(s,p) for (s,p) in zip(dev_sents,dev_parses)]\n",
    "np.random.shuffle(dev_sents_and_parses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7005\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_sents_and_parses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 35\n",
    "unique_sents = set()\n",
    "sent_hopper = []\n",
    "bcount = 0\n",
    "for (s,p) in dev_sents_and_parses:\n",
    "    s = ' '.join(s.strip().split())\n",
    "    if s in unique_sents:\n",
    "        continue\n",
    "    unique_sents.add(s)\n",
    "    sent_hopper.append(s)\n",
    "    if (len(sent_hopper)%batch_size)==0:\n",
    "        bcount += 1\n",
    "        doc = nlp('\\n'.join(sent_hopper))\n",
    "        batch_id = \"nlvr2_dev_{}\".format(str(bcount).zfill(3))\n",
    "        foliadoc = spacy2folia.convert(doc, batch_id, paragraphs=False)\n",
    "        foliadoc.save(\"../../data/folia/dev/{}.folia.xml\".format(batch_id))\n",
    "        sent_hopper = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite FoLiA XML files\n",
    "# without the prep attachments\n",
    "prepdeps = []\n",
    "dep_on = re.compile(r'<dependencies>')\n",
    "dep_off = re.compile(r'<\\/dependencies>')\n",
    "depann_on = re.compile(r'<dependency-annotation.*>')\n",
    "depann_off = re.compile(r'<\\/dependency-annotation>')\n",
    "xmlfiles = []\n",
    "for xmlfile in os.listdir('../../data/folia/dev'):\n",
    "    fnlines = []\n",
    "    with open('../../data/folia/dev/{}'.format(xmlfile)) as fnin:\n",
    "        #print(xmlfile)\n",
    "        doline = True\n",
    "        for line in fnin:\n",
    "            if doline:\n",
    "                fnlines.append(line)\n",
    "                if re.search(dep_on, line) or re.search(depann_on, line):\n",
    "                    doline = False\n",
    "            else:\n",
    "                if re.search(dep_off, line) or re.search(depann_off, line):\n",
    "                    doline = True\n",
    "                    fnlines.append(line)\n",
    "    with open('../../data/folia/dev_stripped/{}'.format(xmlfile), 'w') as fnout:\n",
    "        for line in fnlines:\n",
    "            fnout.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
