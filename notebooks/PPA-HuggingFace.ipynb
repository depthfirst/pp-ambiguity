{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows results of predicting prepositional phrase attachments across a subset of the NLVR2 dataset which has been annotated. \n",
    "\n",
    "The first group of models are trained from the output the large uncased model from BERT with whole word masking. \n",
    "This model was subsequently converted to PyTorch/HuggingFace via command-line. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/bridge/science/laboratory/conda/envs/spacy/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "from itertools import groupby\n",
    "\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append('/bridge/science/AI/nlp/bert')\n",
    "from notebook_source import load_text_file, load_xml_files, generate_tuples\n",
    "from notebook_source import load_folia_xml\n",
    "from notebook_source import find_sentence_from_file, find_sentence_from_word_id\n",
    "from notebook_source import generate_annotated4tpls, generate_sentences_from_4tpls\n",
    "from notebook_source import generate_google_instances, generate_huggingface_instances\n",
    "#import tokenization\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(91768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndir = \"/bridge/data/compositional_semantics/folia/jblackmore/done\"\n",
    "spacydir = \"/bridge/data/compositional_semantics/folia/dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, generator = load_folia_xml(anndir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated4tpls = []\n",
    "tdeps = {}\n",
    "for t,dep in generator():\n",
    "    tdeps[t[2]] = dep\n",
    "    annotated4tpls.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tdeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_sents, spacy_gen = load_folia_xml(spacydir)\n",
    "sdeps = {}\n",
    "spacy4tpls = []\n",
    "for spacy_tpl,sdep in spacy_gen():\n",
    "    sprep = spacy_tpl[2]\n",
    "    sdeps[sprep] = sdep\n",
    "    spacy4tpls.append(spacy_tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sdeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotated4tpls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy4tpls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_eyes = [i for i,a4tpl in enumerate(annotated4tpls) if a4tpl[2] not in sdeps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('is', 'nlvr2_dev_012.text.s.35.w.2', 'VBZ', 'be', True),\n",
       " ('doberman', 'nlvr2_dev_012.text.s.35.w.5', 'NNP', 'doberman', True),\n",
       " ('with', 'nlvr2_dev_012.text.s.35.w.6', 'IN', 'with', True),\n",
       " ('cut', 'nlvr2_dev_012.text.s.35.w.9', 'NN', 'cut', False))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated4tpls[missing_eyes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated4tpls = [a4tpl for i,a4tpl in enumerate(annotated4tpls) if i not in missing_eyes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('flower', 'nlvr2_dev_002.text.s.24.w.6', 'NN', 'flower', True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdeps[annotated4tpls[21][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_attachment_class = lambda tpl, deps : \\\n",
    "    '!' if tpl[2] not in deps else \\\n",
    "    'V' if deps[tpl[2]]==tpl[0] else \\\n",
    "    'N' if deps[tpl[2]]==tpl[1] else \\\n",
    "    'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [prep_attachment_class(tpl,tdeps) for tpl in annotated4tpls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'N': 442, 'V': 140, 'O': 47})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_preds = [prep_attachment_class(tpl,sdeps) for tpl in annotated4tpls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.275600163537006"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa(spacy_preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'V': 94, 'N': 465, 'O': 70})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(spacy_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2\n",
       "0  361  50  31\n",
       "1   95  37   8\n",
       "2    9   7  31"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(confusion_matrix(labels, spacy_preds, labels=['N','V','O']), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_datadir = '/bridge/science/AI/nlp/data/compositional_semantics/BERT'\n",
    "bert_model = 'wwm_uncased_L-24_H-1024_A-16'\n",
    "bert_basedir=\"/bridge/science/AI/nlp/corpora/BERT/wwm_uncased_L-24_H-1024_A-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sents_all = list(generate_sentences_from_4tpls(annotated4tpls,sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from notebook_source import stext\n",
    "#sents_all=[stext(find_sentence_from_word_id(t4tpl[0][1],sents)) for t4tpl in annotated4tpls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(sents_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all sentences with annotations to disk for further\n",
    "# processing with BERT models. \n",
    "\n",
    "#with open(os.path.join(bert_datadir,'sents_all.txt'),'w') as allout:\n",
    "#    for s in sents_all:\n",
    "#        allout.write(s)\n",
    "#        allout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... Wait for features from BERT ...\n",
    "#export BERT_BASE_DIR=/bridge/science/AI/nlp/corpora/BERT/wwm_uncased_L-24_H-1024_A-16\n",
    "#python extract_features.py --input_file=/bridge/science/AI/nlp/data/compositional_semantics/BERT/sents_all.txt --output_file=/bridge/science/AI/nlp/data/compositional_semantics/BERT/sents_all_wwmu_output.jsonl --vocab_file=$BERT_BASE_DIR/vocab.txt --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt --layers=-1,-2,-3,-4 --max_seq_length=128 --batch_size=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(X_list)\n",
    "test_size = int(len(annotated4tpls)/4)\n",
    "randidx = list(range(len(annotated4tpls)))\n",
    "np.random.shuffle(randidx)\n",
    "trainidx = randidx[test_size:]\n",
    "testidx = randidx[:test_size]\n",
    "labels_train = [labels[i] for i in trainidx]\n",
    "labels_test = [labels[i] for i in testidx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /bridge/science/AI/nlp/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonl_file = os.path.join(bert_datadir,'sents_all_wwmu_output.jsonl')\n",
    "sents_all = list(generate_sentences_from_4tpls(annotated4tpls,sents))\n",
    "X_goog = [x for x in generate_google_instances(annotated4tpls, sents,jsonl_file,labels=labels, omit_indexes=missing_eyes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_goog = np.array(X_goog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_goog[trainidx]\n",
    "test = X_goog[testidx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=91768, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.0001, C=100., random_state=91768)\n",
    "\n",
    "clf.fit(train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.595881595881596"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa(labels_test, clf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'N': 111, 'V': 36, 'O': 10})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the same BERT model to work with huggingface with a command-line based converter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export HF_MODEL_DIR=\"/bridge/science/AI/nlp/bert/huggingface\"\n",
    "#transformers-cli convert --model_type bert --tf_checkpoint $BERT_BASE_DIR/bert_model.ckpt --config $BERT_BASE_DIR/bert_config.json --pytorch_dump_output $HF_MODEL_DIR/pytorch_model.bin\n",
    "hf_model_dir=\"/bridge/science/AI/nlp/bert/huggingface\"\n",
    "hf_model_file=os.path.join(hf_model_dir,\"pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to load the same BERT model through the huggingface\n",
    "transformers API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to stack these in such a way that layers 4-3-2-1 appear for each of the 4 words, selected across word pieces. \n",
    "\n",
    "Ex: <br>\n",
    "Mary ate noodles with chopsticks. <br>\n",
    "Mary ate noodles with curry. <br>\n",
    "\n",
    "4-tuple (VNPN): ate, noodles, with, (chopsticks/curry)\n",
    "\n",
    "The BERT tokenizer may break up words, so it's possible to see something like \n",
    "ate,noodl#es, with, chop#sticks/cur#ry\n",
    "We take the 4 layers of up to 4 pieces of each word, starting with the \n",
    "4th layer of the first piece, then the\n",
    "3rd layer of the second/last piece, ...\n",
    "top layer of the fourth/last piece, \n",
    "So we'll have 16 piece-layers for each attachment instance. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swapping in the huggingface.co model (easy)\n",
    "# Load pre-trained model (weights)\n",
    "#config = BertConfig.from_pretrained(\"bert-large-uncased-whole-word-masking\")\n",
    "xconfig = BertConfig.from_pretrained(os.path.join(hf_model_dir,\"config.json\"))\n",
    "xconfig.output_hidden_states=True\n",
    "\n",
    "#hfxmodel = BertModel.from_pretrained(config=xconfig)\n",
    "hfxmodel = BertModel.from_pretrained(hf_model_file,config=xconfig)\n",
    "hfxmodel.eval()\n",
    "\n",
    "hfxtokenizer = BertTokenizer.from_pretrained(hf_model_dir, config=xconfig)\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking')\n",
    "#hftokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.array([x for x in generate_huggingface_instances(\n",
    "    hfxmodel,hfxtokenizer,annotated4tpls,sents,labels,use_cuda=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629, 16384)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf = XX[trainidx]\n",
    "test_hf = XX[testidx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=91768, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfhf = svm.SVC(gamma=0.0001, C=100., random_state=91768)\n",
    "\n",
    "clfhf.fit(train_hf, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134147542598247"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test_hf = clfhf.predict(test_hf)\n",
    "kappa(labels_test, labels_test_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export HF_MODEL_DIR=\"/bridge/science/AI/nlp/bert/huggingface\"\n",
    "#transformers-cli convert --model_type bert --tf_checkpoint $BERT_BASE_DIR/bert_model.ckpt --config $BERT_BASE_DIR/bert_config.json --pytorch_dump_output $HF_MODEL_DIR/pytorch_model.bin\n",
    "hf2_model_dir=\"/bridge/science/AI/nlp/bert/model/pytorch-1600\"\n",
    "hf2_model_file=os.path.join(hf2_model_dir,\"pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swapping in the huggingface.co model (easy)\n",
    "# Load pre-trained model (weights)\n",
    "#config = BertConfig.from_pretrained(\"bert-large-uncased-whole-word-masking\")\n",
    "x2config = BertConfig.from_pretrained(os.path.join(hf2_model_dir,\"config.json\"))\n",
    "x2config.output_hidden_states=True\n",
    "\n",
    "#hfxmodel = BertModel.from_pretrained(config=xconfig)\n",
    "hfxmodel = BertModel.from_pretrained(hf2_model_file,config=x2config)\n",
    "hfxmodel.eval()\n",
    "\n",
    "hf2tokenizer = BertTokenizer.from_pretrained(hf2_model_dir, config=x2config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX2 = np.array([x for x in generate_huggingface_instances(\n",
    "    hfxmodel,hf2tokenizer,annotated4tpls,sents,labels,use_cuda=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf2 = XX2[trainidx]\n",
    "test_hf2 = XX2[testidx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=91768, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfhf2 = svm.SVC(gamma=0.0001, C=100., random_state=91768)\n",
    "\n",
    "clfhf2.fit(train_hf2, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025718914540299"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test_hf2 = clfhf2.predict(test_hf2)\n",
    "kappa(labels_test, labels_test_hf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
