{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolving Ambiguity in Prepositional Phrase Attachment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of resolving ambiguity in prepositional phrase attachment is one that remains largely unsolved in NLP, and one that pre-trained language models such as BERT will likely not be of much help with. This notebook shows results of predicting prepositional phrase attachments across a subset of the NLVR2 dataset which has been annotated, leveraging a pre-trained language model commonly known as \"BERT\" (cite). \n",
    "\n",
    "We trained an SVM classifier from the output (hidden layers) of the large uncased model from BERT with whole word masking. The results are presented in terms of Cohen's kappa score and F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n python=3.7 ...\n",
    "# pip install transformers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score as kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import HuggingFaceGenerator, CountVectorizerGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(91768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data\"\n",
    "outputdir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open('{}/ppa_train.json'.format(datadir)))\n",
    "labels_train = [instance['label'] for instance in train_data]\n",
    "\n",
    "test_data = json.load(open('{}/ppa_test.json'.format(datadir)))\n",
    "labels_test = [instance['label'] for instance in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT Language Model\n",
    "We load a pre-trained model from BERT and use it to generate instances for model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"bert-large-uncased-whole-word-masking\"\n",
    "hf_generator = HuggingFaceGenerator(bert_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Dataset (or reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_file = \"{}/hf_train.csv\".format(outputdir)\n",
    "test_feature_file = \"{}/hf_test.csv\".format(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(train_feature_file):\n",
    "    hf_train = pd.read_csv(train_feature_file, header=None)\n",
    "else:\n",
    "    hf_train = hf_generator.generate_dataset(train_data)\n",
    "    pd.DataFrame(hf_train).to_csv(train_feature_file, header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(test_feature_file):\n",
    "    hf_test = pd.read_csv(test_feature_file, header=None)\n",
    "else:\n",
    "    hf_test = hf_generator.generate_dataset(test_data)\n",
    "    pd.DataFrame(hf_test).to_csv(test_feature_file, header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=91768, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfhf = svm.SVC(gamma=0.0001, C=100., random_state=91768)\n",
    "clfhf.fit(hf_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_hf = clfhf.predict(hf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90909091, 0.68656716, 0.5       ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(labels_test, preds_test_hf, labels=['N','V','O'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134147542598247"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa(labels_test, preds_test_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the new stuff... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlvr2_datadir = \"/bridge/data/compositional_semantics/nlvr2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import MaskedPrepGenerator, NLVR2SentenceGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpgen = MaskedPrepGenerator(bert_model_name,nlvr2_datadir=nlvr2_datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev, 2004 instances\n",
      "(78 correct / 100 total)\n",
      "(159 correct / 200 total)\n",
      "(234 correct / 300 total)\n",
      "(314 correct / 400 total)\n",
      "(389 correct / 500 total)\n",
      "(466 correct / 600 total)\n",
      "(551 correct / 700 total)\n",
      "(633 correct / 800 total)\n",
      "(711 correct / 900 total)\n",
      "(785 correct / 1000 total)\n",
      "(860 correct / 1100 total)\n",
      "(936 correct / 1200 total)\n",
      "(1018 correct / 1300 total)\n",
      "(1090 correct / 1400 total)\n",
      "(1167 correct / 1500 total)\n",
      "(1246 correct / 1600 total)\n",
      "(1327 correct / 1700 total)\n",
      "(1406 correct / 1800 total)\n",
      "(1482 correct / 1900 total)\n",
      "(1555 correct / 2000 total)\n",
      "(1639 correct / 2100 total)\n",
      "(1720 correct / 2200 total)\n",
      "(1795 correct / 2300 total)\n",
      "(1875 correct / 2400 total)\n",
      "(1954 correct / 2500 total)\n",
      "(2032 correct / 2600 total)\n",
      "(2114 correct / 2700 total)\n",
      "(2191 correct / 2800 total)\n",
      "(2270 correct / 2900 total)\n",
      "(2345 correct / 3000 total)\n",
      "(2424 correct / 3100 total)\n",
      "(2499 correct / 3200 total)\n",
      "(2573 correct / 3300 total)\n",
      "(2648 correct / 3400 total)\n",
      "(2729 correct / 3500 total)\n",
      "(2808 correct / 3600 total)\n",
      "(2889 correct / 3700 total)\n",
      "(2972 correct / 3800 total)\n",
      "(3048 correct / 3900 total)\n"
     ]
    }
   ],
   "source": [
    "num_correct,num_total=mpgen.evaluate_dataset(settype=\"dev\",use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78067\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.5f}\".format(num_correct/num_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
